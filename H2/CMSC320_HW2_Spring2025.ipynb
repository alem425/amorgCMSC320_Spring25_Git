{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKLgKS1btvRB"
   },
   "source": [
    "# **HOMEWORK 2: BRAIN CONDITIONING STATS** ðŸ“Š\n",
    "## **DUE: *March 04, 2025 @ 11:59 PM***\n",
    "## **24-HR LATE DUE DATE WITH A 15% PENALTY: *March 5, 2025 @ 11:59 PM***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQmzLo3dt1Hm"
   },
   "source": [
    "**Objective:**  \n",
    "\n",
    "The aim of this assignment is to deepen students' understanding of statistics and hypothesis testing using Python. By engaging with some theortical questions as well as practical exercises, students will apply statistical methods and perform hypothesis tests, using Python to code and execute these techniques. This approach will help solidify their grasp of statistical principles and their application in Python, bridging theoretical knowledge with practical skills.\n",
    "\n",
    "### **Reminder: Please make sure your code runs before submitting your work. Code sections that do not run will receive 0 credits, no partials will be given. This is VERY important in real project development.**\n",
    "### **DO NOT REMOVE ANY PART OF ANY OF THE QUESTIONS OR YOU LOSE CREDIT**\n",
    "### *No Hardcoding either*  ðŸ˜‹ðŸ“‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhnhliH6Fdga"
   },
   "source": [
    "# **Part 1: Statistics Problem Solving**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwJSnRGwG2p7"
   },
   "source": [
    "##Q1) (10 POINTS) Bayes Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDMy_c7bGSFq"
   },
   "source": [
    "Suppose some hacker found a dataset on uselessdatasets.com containing information about three different types of users on an online platform: \"bloggers\", \"shoppers\", and \"reviewers\". The data has 10,000 users. There are 4,500 bloggers, 6,000 shoppers, and 5,500 reviewers. The users could be in multiple categories. 2,000 of the bloggers are shoppers, 1,800 of the bloggers are reviewers, and 3,000 shoppers are also reviewers.\n",
    "\n",
    "Answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpJaCCIWHb-q"
   },
   "source": [
    "1. (3 POINTS) If $X$ is a random variable that represents the users that were cross listed into all 3 categories, what is the value of $X$? (Hint: think of a Venn Diagram.)\n",
    "\n",
    "> Write down you answer: X = 800 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSI0rgMFHeqV"
   },
   "source": [
    "2. (3 POINTS) Calculate the probability that a randomly selected shopper is also a reviewer. (Hint: Use Bayes Theorem)\n",
    "\n",
    "> Write down your answer. P(r|s) = 1/2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdwmsNa_Hexi"
   },
   "source": [
    "3. (4 POINTS) Calculate the probability that a random user is in exactly two categories but not all three.\n",
    "\n",
    "> Write down your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY38nVLZIL0O"
   },
   "source": [
    "##Q2) (6 POINTS) Expected Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8XTaX1Lcg1T"
   },
   "source": [
    "Let $T$ be the set of all sequences of two rolls of a dice. Let $S$ be the set of all sequences of three rolls of a dice. Let $X_n$ be the sum of the number of dots on $n$ dice rolls.\n",
    "\n",
    "Answer the following question:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJGNtK5eck07"
   },
   "source": [
    "1. (3 POINTS) What is $\\mathbb{E}[X_2]$?\n",
    "\n",
    "> Write down your answer. 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2GzKvNAcuKD"
   },
   "source": [
    "2. (3 POINTS) What is $\\mathbb{E}[X_3]$?\n",
    "\n",
    "> Write down your answer. 10.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lrY31ZOc6cV"
   },
   "source": [
    "##Q3) (6 POINTS) Probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5i8SGbTPdAB9"
   },
   "source": [
    "Let  $X$  be a continuous random variable that follows a normal distribution with mean  $\\mu = 10$  and standard deviation  $\\sigma = 2$.\n",
    "\n",
    "Answer the following question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBWOOR8RdMRQ"
   },
   "source": [
    "1. (3 POINTS) What is the probability that $X$ takes a value between 8 and 12?\n",
    "Hints: You may have to utilize the standard normal table: https://math.arizona.edu/~jwatkins/normal-table.pdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> **How to read the \"Standard Normal Cumulative Probability Table\" table:**\n",
    "\n",
    "\n",
    "*   Rows and Columns: The rows correspond to the first digit and first decimal place of z. The columns correspond to the second decimal place of z.\n",
    "*   Check out: https://byjus.com/maths/z-score-table/\n",
    "\n",
    "\n",
    "\n",
    "> Write down your answer. 0.6826\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk5gSI7Yhbgi"
   },
   "source": [
    "2. (3 POINTS) What is the probability that $X$ takes a value greater than 14?\n",
    "\n",
    "> Write down your answer. 0.0228\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd62j-z1FlKj"
   },
   "source": [
    "# **Part 2: Python Warmups**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtrQ-Vrdczic"
   },
   "source": [
    "##Q1) (10 POINTS) Bernoulli Trials\n",
    "\n",
    "Consider a sequence of $n$ Bernoulli trials with success probability $p$ per trial. A string of consecutive successes is known as a *streak*.\n",
    "\n",
    "> **Task to do:** Write a function that returns a `collections.Counter` that maps the length of a streak $k$ to the number of times it is observed in an input sequence `xs`. For example, if `xs = [0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1]`, the output would be `Counter({1: 2, 2: 1, 3: 2})`. We have imported `Counter` from the Python `collections` library for you in the code block below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "EjCkESEmc9Cz"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_streaks(xs):\n",
    "    \"\"\"Count number of success runs of length k.\"\"\"\n",
    "    current_streak = 0\n",
    "    counts = Counter()\n",
    "    for x in xs:\n",
    "        if x == 1:\n",
    "            current_streak += 1\n",
    "        else:\n",
    "            if current_streak > 0:\n",
    "                counts[current_streak] += 1\n",
    "                current_streak = 0\n",
    "    # Check for a streak that ends the sequence\n",
    "    if current_streak > 0:\n",
    "        counts[current_streak] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "J2w_2uB7dQin"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Use this cell to test your answer. MAKE SURE YOUR RESULTS ARE SHOWN BELOW AFTER RUNNING THIS BOX\n",
    "import numpy as np\n",
    "print(count_streaks([0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1]))\n",
    "np.random.seed(0)\n",
    "count_streaks(np.random.randint(0,2,1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soG82SCihwDT"
   },
   "source": [
    "##Q2) (10 POINTS) Distribution and Visualization\n",
    "\n",
    "The goal of solving this problem is to become familiar with using built-in Python libraries to create various distributions. Plotting serves as an initial step toward data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh5maPG3iKSZ"
   },
   "source": [
    "1. (3 POINTS) Create a normally distributed random variable with mean $\\mu = 0$, standard deviation $\\sigma = 5$ and sample size $n=1000$. Plot the histogram. Add labels and titles and other details as desired to make your plot understandable. You must use the packages `numpy` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "GGE_YQ2eiJPh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "mu = 0      # Mean\n",
    "sigma = 5   # Standard deviation\n",
    "size = 1000 # Number of samples\n",
    "\n",
    "# Generate random samples\n",
    "samples = np.random.normal(mu, sigma, size)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(samples, bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of samples')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WZvmUTZmx11"
   },
   "source": [
    "2. (7 POINTS) We are exploring the Central Limit Theorem (CLT) using a Poisson distribution. Suppose you have a population that follows a Poisson distribution with a rate parameter (or mean)  $\\lambda = 3$ . You will draw multiple samples from this population and calculate the mean of each sample.\n",
    "\n",
    "Write a Python function that simulates this process. The input of the function should be the sample size, the number of samples, and lambda. The function should:\n",
    "1. Generate a population with a Poisson distribution (check: https://numpy.org/doc/stable/reference/random/generated/numpy.random.poisson.html).\n",
    "2. Draw multiple samples and calculate the mean of each sample.\n",
    "3. Return these means as an iterable.\n",
    "\n",
    "*There will be no partial credit granted for this question. Any hardcoded results will receive a 0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "Q7HqSg1AnHy4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def poisson_clt_simulator(sample_size, num_samples, lambda_):\n",
    "    sample_means = []\n",
    "    for _ in range(num_samples):\n",
    "        sample = np.random.poisson(lambda_,sample_size)\n",
    "        sample_means.append(np.mean(sample)) # Think carefully what you are appending here, refer to variable name\n",
    "    return sample_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcIu1vJCqUTj"
   },
   "source": [
    "  Now use the function to generate 1,000 sample means with sample size 50. Plot the distribution of these sample means to visualize the Central Limit Theorem. Add labels and titles and other details as desired to make your plot understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "jWy2qFXtrfSm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "sample_size = 50\n",
    "num_samples = 1000\n",
    "lambda_ = 3\n",
    "\n",
    "# Simulate and get sample means\n",
    "sample_means = poisson_clt_simulator(sample_size, num_samples, lambda_)\n",
    "print(sample_means)\n",
    "# Plot the distribution of sample means\n",
    "plt.hist(sample_means)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Sample Mean')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Sample Means (CLT Visualization for Poisson)')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vIf9sj-rAuk"
   },
   "source": [
    "##Q3) (18 POINTS) More on Distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbpadK721M9L"
   },
   "source": [
    "You can't get around with distributions while data sciencing. Let's explore how distributions are related to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSNFwHvQ111k"
   },
   "source": [
    "**1. (6 POINTS)** Since we have successfully demonstrated how CLT works, lets see what we can do with it.\n",
    "\n",
    "*Check out https://numpy.org/doc/stable/reference/random/generated/numpy.random.binomial.html for how to create independent binomial distributions*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l41MNSr63cZG"
   },
   "source": [
    "\n",
    "**TASK:** Show that a Binomial$( n, p )$ distribution approximates a Normal distribution when n is LARGE (due to CLT).\n",
    "Complete the following code according to comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "6e--jGg14BLg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "size = 10000\n",
    "n, p = 50, 0.5  # Large n for normal approximation\n",
    "binomial_samples = np.random.binomial(n, p, size)\n",
    "normal_samples = np.random.normal(loc=n*p, scale=np.sqrt(n*p*(1-p)), size=size) # Don't worry about this line unless you are interested\n",
    "\n",
    "plt.hist(binomial_samples, bins=50, density=True, alpha=0.6, label=\"Binomial(50,0.5)\")\n",
    "plt.hist(normal_samples, bins=50, density=True, alpha=0.6, label=\"Normal Approximation\")\n",
    "plt.legend()\n",
    "plt.title(\"Binomial vs. Normal Approximation\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrcwdGRf5Ug0"
   },
   "source": [
    "**2. (6 POINTS)** Now with Poisson\n",
    "\n",
    "*Check out https://numpy.org/doc/stable/reference/random/generated/numpy.random.poisson.html for how to create independent poisson distributions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dso81KYy5zt9"
   },
   "source": [
    "**TASK:** Show that when n is large and p is small, a Binomial$( n, p )$ distribution approximates a Poisson distribution with  $\\lambda = np$.\n",
    "Complete the following code according to comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "kA4nORaM6QhT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "size = 10000\n",
    "n, p = 100, 0.05  # np = 5, small p\n",
    "binomial_samples = np.random.binomial(n, p, size)\n",
    "poisson_samples = np.random.poisson(n*p, size)\n",
    "\n",
    "plt.hist(binomial_samples, bins=20, density=True, alpha=0.6, label=\"Binomial(100, 0.05)\")\n",
    "plt.hist(poisson_samples, bins=20, density=True, alpha=0.6, label=\"Poisson(Î»=5)\")\n",
    "plt.legend()\n",
    "plt.title(\"Poisson Approximation to Binomial\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6bGAi_f7oXX"
   },
   "source": [
    "**3. (6 POINTS)** Poisson and Exponential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i5TaSYL7zDv"
   },
   "source": [
    "We know that Poisson counts the number of arrivals, while Exponential models the time between them.\n",
    "\n",
    "**TASK:** Plot a Poisson distribution and an Exponential distribution. You do not have to describe and justify your findings.\n",
    "\n",
    "*Check out https://numpy.org/doc/stable/reference/random/generated/numpy.random.exponential.html *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H58TflBzD3Sd"
   },
   "source": [
    "> **NOTES: **If you dont know about Exponensial Distribution, check out:\n",
    "\n",
    "\n",
    "*   https://www.probabilitycourse.com/chapter4/4_2_2_exponential.php\n",
    "*   https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/business/probability/exponential-distribution.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRdCRFyJD3nC"
   },
   "source": [
    "Complete the following code according to comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "CxtOzsiJ8H-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "size = 10000\n",
    "lambda_exp = 3  # rate for Poisson\n",
    "# The variable name might be tricky, but think carefully exactly what Poisson represents\n",
    "poisson_time_intervals = np.random.poisson(lambda_exp, size) \n",
    "# What is the scale of exponential, and how is it related to lambda?\n",
    "exponential_samples = np.random.exponential(1/lambda_exp, size)\n",
    "\n",
    "plt.hist(exponential_samples, bins=50, density=True, alpha=0.6, label=\"Exponential\")\n",
    "plt.legend()\n",
    "plt.title(\"Exponential Distribution as Interarrival Times\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8O0YGnV4Cbp"
   },
   "source": [
    "# **Part 3: Hypothesis Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr1gnMPH4K95"
   },
   "source": [
    "##Q1) (14 POINTS) Hypothesis Tests and P_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp9tnOacNuMX"
   },
   "source": [
    "**TASK:** For the next 5 problems, please describe when you would use each hypothesis test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMYJ8tll4cTM"
   },
   "source": [
    "\n",
    "\n",
    "*   Chi-Squared Test\n",
    "*   Z test\n",
    "*   T test\n",
    "*   Mann-Whitney U Test\n",
    "*   Anova\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pkn-uG4cETC9"
   },
   "source": [
    "1.1  (2 POINTS) Chi-Squared Test\n",
    "\n",
    "> Write down your answer. Used to find out if there's a big association between two categorical variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lxfrp1xuEYzi"
   },
   "source": [
    "1.2  (2 POINTS) Z-Test\n",
    "\n",
    "\n",
    "> Write down your answer. Compares the sample mean to the population mean when the sample size is large (n â‰¥ 30).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbsWX4fxEZBg"
   },
   "source": [
    "1.3  (2 POINTS) T-Test\n",
    "\n",
    "\n",
    "> Write down your answer. Same as Z-Test but when the sample size is small (n <30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YegV9lSFEZO6"
   },
   "source": [
    "1.4  (2 POINTS) Man-Whitney U Test\n",
    "\n",
    "\n",
    "> Write down your answer. Used for non-parametric data to compare the medians of two independent groups when normality cannot be assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpPZpmtMEZfS"
   },
   "source": [
    "1.5  (2 POINTS) ANOVA Test\n",
    "\n",
    "\n",
    "> Write down your answer. Compares the means of three or more groups to determine if there are significant differences overall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdYe6uWWKPtd"
   },
   "source": [
    "**1.6 (4 POINTS) :** Explain the statistical interpretation of a p-value. What is a p-value? What does it mean? Be sure to explain beyond just \"rejecting or failing to reject the null hypothesis.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zhdjJyjK1D7"
   },
   "source": [
    "> Write down your answer. The p-value is a tool for finding the likelihood of observed data under the null hypothesis, helping in informed decision-making. However, it must be used in proper circumstances, considering study design and potential pitfalls, to make sure you get robust and reliable conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "va2vA-in5dWy"
   },
   "source": [
    "##Q2)  (2 POINTS) Create a DataFrame and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "Ijr5bfGL5_l1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqbjlGP6xFnm"
   },
   "source": [
    "### We are creating a DataFrame `df`. Load `colleges.csv` and display the DataFrame below.\n",
    "This college dataset contains a list of American colleges and their rankings, along with other details such as region, college type, student-to-faculty ratio, etc. In the sections below, you will develop hypotheses, test them, and draw conclusions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "gYOPX768xFnm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Your code here\n",
    "df=pd.read_csv('colleges.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc36rSvHxFnn"
   },
   "source": [
    "**TASK 2.1 (2 POINTS):** Some entries of the dataframe are NaN. remove those entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "uGDjmtvMxFnn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Your code here\n",
    "df_cleaned = df.dropna()\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcqr3fjkxFnn"
   },
   "source": [
    "#Q3)  (8 POINTS) Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJseQzaaxFnn"
   },
   "source": [
    "Try to find relationships in this dataset through hypothesis testing. For each hypothesis test:\n",
    "\n",
    "- First chose a null hypothesis, or a statement that there is no effect between different variables, that serves as a default assumption.\n",
    "\n",
    "- Then chose an alternative hypothesis, or a statement that suggests that there is a correlation between different variables.\n",
    "\n",
    "For the questions below, assume $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJlwAeQCxFnn"
   },
   "source": [
    "## First Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTzMNuzOxFnn"
   },
   "source": [
    "- HO: The region of the college does not have an effect on the likelihood of the college type.\n",
    "\n",
    "- HA: The region of the college does have an effect on the likelihood of the college type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAJ5Ys87xFnn"
   },
   "source": [
    "Our plan is to apply a chi-squared test. You may find it helpful to consult the `scipy.stats` library's documentation:\n",
    "https://docs.scipy.org/doc/scipy/reference/stats.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejZSrDUVxFnn"
   },
   "source": [
    "Contingency table is a table used in statistics to display the frequency distribution of variables. It will help us perform a chi-squared test on our data. You can find more information on contingency table here - https://en.wikipedia.org/wiki/Contingency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdZi1x-UxFnn"
   },
   "source": [
    "**TASK 3.1 (2 POINTS)**: Create a contingency table and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "Mge-6Jh2xFnn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "contingency_table = pd.crosstab(index=df['region'], columns='region')\n",
    "contingency_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-299BtA5xFno"
   },
   "source": [
    "**TASK 3.2 (2 POINTS)**: Why would we consider using a chi-squared test specifically (as opposed to some other hypothesis test)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6BLDJ7kxFno"
   },
   "source": [
    "> Write down your answer. It evaluates associations between two categorical variables, which works for our scenario of examining how the college region affects college type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_4Y0c3rxFno"
   },
   "source": [
    "**TASK 3.3 (2 POINTS)**: Create a plot showing the relationship between the regions and the no. of private colleges in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "X9I0g6Q7xFnq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "# Any graph that can be easily identified as the prompt above is suffice\n",
    "\n",
    "df = pd.read_csv('colleges.csv')\n",
    "\n",
    "print(df['collegeType'].unique())\n",
    "\n",
    "# Filter for private colleges\n",
    "private_colleges = df[df['collegeType'] == 'Private not-for-profit']\n",
    "\n",
    "# Count the number of private colleges in each region\n",
    "region_counts = private_colleges['region'].value_counts()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "region_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Number of Private Colleges by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of Private Colleges')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlzi9e3jxFnq"
   },
   "source": [
    "**TASK 3.4 (2 POINTS)**: Explain what you can infer from your plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C0XA1bRxFnq"
   },
   "source": [
    "> Write down your answer. We See that the Northeast holds a vast amount of private colleges, which would make sense as colleges around the time of the 13 Colonies were all private the other regions are close in comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf8VFmFuxFnq"
   },
   "source": [
    "#Q4) (5 POINTS) Conduct the chi-squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4L1JOyaxFnq"
   },
   "source": [
    "**TASK: 4.1 (2 POINTS):** Display the p-value of applying the chi-squared test using the `chi2_contingency()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "b0o_ZJ93xFnq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# Your code here\n",
    "df = pd.read_csv('colleges.csv')\n",
    "\n",
    "# Create a contingency table for the chi-squared test\n",
    "contingency_table = pd.crosstab(df['region'], df['collegeType'])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "\n",
    "print(f'P-Value: {p}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egAsKCedxFnq"
   },
   "source": [
    "**TASK: 4.2  (3 POINTS)**: Based on the p-value, determine whether to reject or fail to reject the null hypothesis. Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zGZziq1xFnq"
   },
   "source": [
    "\n",
    "> Write down your answer. We should reject the null hypothesis because our p-val is < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7KycKn1xFnq"
   },
   "source": [
    "#Q5) (3 POINTS) A New Hypothesis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq50I4tfxFnq"
   },
   "source": [
    "Now create a new hypothesis test for whether the campus setting has an effect on the total student population. (Assume $\\alpha=0.05$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ2FFcYxxFnq"
   },
   "source": [
    "**TASK 5.1  (3 POINTS)**: Write down your null and alternative hypotheses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1mWab_kxFnq"
   },
   "source": [
    "> Your answer here Null Hypothesis (H0): The campus setting has no effect on the total student population. In other words, the mean total student population is the same across different campus settings.\n",
    "\n",
    "Alternative Hypothesis (H1): The campus setting has an effect on the total student population. In other words, the mean total student population is different across different campus settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "za_l19WtxFnr"
   },
   "source": [
    "#Q6) (7 POINTS) Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs0sI7xtxFnr"
   },
   "source": [
    "**TASK 6.0**: Split the data into 3 different dataframes based on campus setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "ZMbBhrotxFnr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "urban= df[df['campusSetting'] == 'Urban']\n",
    "suburban = df[df['campusSetting'] == 'Suburban']\n",
    "rural = df[df['campusSetting'] == 'Rural']\n",
    "\n",
    "print(\"Urban DataFrame:\")\n",
    "print(urban.head())\n",
    "\n",
    "print(\"\\nSuburban DataFrame:\")\n",
    "print(suburban.head())\n",
    "\n",
    "print(\"\\nRural DataFrame:\")\n",
    "print(rural.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4E_BV9pxFnr"
   },
   "source": [
    "**TASK 6.1 (2 POINTS)**: Choose an appropriate hypothesis test and display the p-value of applying the that test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "jXkIU-7QxFnr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "# YOUR CODE HERE\n",
    "urbanStudents = urban['totalStudentPop']\n",
    "suburbanStudents = suburban['totalStudentPop']\n",
    "ruralStudents = rural['totalStudentPop']\n",
    "\n",
    "#ANOVA test\n",
    "p_value = f_oneway(urbanStudents, suburbanStudents, ruralStudents)\n",
    "\n",
    "print(f'P-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2mibvwoxFnr"
   },
   "source": [
    "**TASK 6.2 \\(2 POINTS)**: Create a graph(s) using `matplotlib` to show the relationship between campus setting and total student population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "OZMWcPe5xFnr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a box plot to show the relationship between campus setting and total student population\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.boxplot(column='totalStudentPop', by='campusSetting', grid=False)\n",
    "plt.title('Total Student Population by Campus Setting')\n",
    "plt.suptitle('')  # Suppress the default title to avoid overlap\n",
    "plt.xlabel('Campus Setting')\n",
    "plt.ylabel('Total Student Population')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0Um94_oxFnr"
   },
   "source": [
    "**TASK 6.3 (3 POINTS)**: Based on the p-value, determine whether to reject or fail to reject the null hypothesis. Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GX2XXD6nxFnr"
   },
   "source": [
    "\n",
    "\n",
    "> Answer here:\n",
    "We fail to reject the null hypothesis since p >= alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhaiFV4ExFns"
   },
   "source": [
    "#*Q7)* (2 POINTS) Post Hoc Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0-x_HCFxFns"
   },
   "source": [
    "**TASK 7.1 (2 POINTS)**: Why might we need post-hoc tests in this scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIwW7JQrxFns"
   },
   "source": [
    "\n",
    "\n",
    "> Answer Here:\n",
    "post-hoc tests can still serve valuable purposes, particularly in exploring and refining hypotheses, addressing low power, enhancing understanding, and meeting field-specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sro6I621xFns"
   },
   "source": [
    "**BONUS TASK 7.2 (2+1=3 POINTS)**: Apply a post-hoc test of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "8rTml3SFxFns"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXlCEG3oxFns"
   },
   "source": [
    "\n",
    "> Write your interpretation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOGvXsMMxFns"
   },
   "source": [
    "#*Q8)* (19 POINTS) Hypothesis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMLrOKZuxFns"
   },
   "source": [
    "Now create a new hypothesis test for whether the total grant aid has an affect on college ranking. (Assume $\\alpha=0.05$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFF_U9AWxFns"
   },
   "source": [
    "**TASK 8.1 (3 POINTS):** Write down the null and alternative hypotheses below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUxyOW_ixFns"
   },
   "source": [
    "> Your answer here:\n",
    " Null Hypothesis (H0): There is no significant effect of total grant aid on college ranking.\n",
    "\n",
    "Alternative Hypothesis (H1): There is a significant effect of total grant aid on college ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHWLCbAUxFns"
   },
   "source": [
    "**TASK 8.2 (2 POINTS)**: Create a plot using `matplotlib` that visualizes your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "xBmWdOcyxFns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "plt.scatter(df['totalGrantAid'], df['rank'])\n",
    "plt.xlabel('Total Grant Aid')\n",
    "plt.ylabel('College Ranking')\n",
    "plt.title('Scatter Plot of Total Grant Aid vs College Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StNwKUVJxFnt"
   },
   "source": [
    "**TASK 8.3 (3 POINTS):** Apply an appropriate hypothesis test and find the p-value of the it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "tpdna42ixFnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlation, p_value = pearsonr(df['totalGrantAid'], df['rank'])\n",
    "\n",
    "print(f'Correlation coefficient: {correlation}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# Determine if we reject the null hypothesis\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant effect of total grant aid on college ranking.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant effect of total grant aid on college ranking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFYuzjUWxFnt"
   },
   "source": [
    "**TASK 8.4 (3 POINTS)**: Based on the p-value, determine whether to reject or fail to reject the null hypothesis. Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG-EBQjrxFnt"
   },
   "source": [
    "\n",
    "\n",
    "> Answer Here\n",
    "Fail to reject the null hypothesis due to there being a nan pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyAgGFmExFnt"
   },
   "source": [
    "**TASK 8.5 (3 POINTS)**: Based on your previous answer, can you conclude that increasing grant aid will change a college's ranking? What is experimental procedure required to reach this conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VwlIpPfxFnt"
   },
   "source": [
    "\n",
    "\n",
    "> Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLEPhp1rxFnt"
   },
   "source": [
    "**TASK 8.6 (3 POINTS)**: What kind of t-test (right-tail or left-tail) would you use to verify the following hypothesis?\n",
    "\n",
    "*H0:* There is no difference in student to faculty ratio between private and public colleges\n",
    "\n",
    "*HA:* Private colleges have a smaller student to faculty ratio\n",
    "\n",
    "Also perform the test and print your p value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtU-m-y_xFnt"
   },
   "source": [
    "> Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "GeiVGY2DxFnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# your code here\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "privateColleges = df[df['collegeType'] == 'private']['studentFacultyRatio']\n",
    "publicColleges = df[df['collegeType'] == 'public']['studentFacultyRatio']\n",
    "\n",
    "# Perform a left-tailed t-test\n",
    "t_stat, p_value = ttest_ind(privateColleges, publicColleges, alternative='less')\n",
    "\n",
    "print(f'T-statistic: {t_stat}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# Determine if we reject the null hypothesis\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: Private colleges have a smaller student to faculty ratio.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in student to faculty ratio between private and public colleges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4B_dxvhxFnt"
   },
   "source": [
    "**TASK 8.7 (2 POINTS)**: Based on the p-value, determine whether to reject or fail to reject the null hypothesis. Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-r9f5MtxFnt"
   },
   "source": [
    "> Your answer here: Fail to reject the null hypothesis due to there being a nan pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wEskV8cCmED"
   },
   "source": [
    "# THE END!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1H9gH1I0FWR7fGhiJT1tt3NqcdnGqTSGl",
     "timestamp": 1709100369675
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
